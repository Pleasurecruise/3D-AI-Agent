# 3D-AI-Agent
## Overview

This project aims to create an AI agent capable of expressing a range of emotions through facial expressions and tone of voice, using Large Language Models (LLMs) and Large Vision Models (LVMs). 

The agent will feature a 3D face model for realistic visualization, enhancing emotional authenticity and interaction. By tackling the challenges of real-time emotion synthesis, this project offers students hands-on experience with advanced AI, visual modelling, and natural language processing to build a more life-like and empathetic AI interaction.

Tasks to be done:

- Develop an avatar with the ability to display a range of facial expressions using Unity3D.
- Integrate LLMs (such as Chat GPT) into the avatar to enable voice interaction accompanied by corresponding facial expressions.
- Upon successful completion of the above, implement additional hand gestures to “upgrade” the avatar.

## Project Period

25/02/17 - 25/05/30

## ASR

funasr

openai-whisper

paddleasr

## TTS

chattts

cosyvoice2

## LLM

Deepseek

ChatGPT

## LVM

Deepface

## TODO List

- [ ] Unity 3D Body Model

## Contributor

- `Minpei LIN`
- `Shuo ZHANG`
- `Yiming WANG`
- `Yihan ZHANG`
- `Zigeng GUO`

supervisor: BOON GIIN LEE

## Acknowledge

1. We borrowed a lot of code from [Fay](https://github.com/xszyou/Fay).
2. We borrowed a lot of code from [CosyVoice](https://github.com/FunAudioLLM/CosyVoice).
3. We borrowed a lot of code from [FunASR](https://github.com/modelscope/FunASR).
