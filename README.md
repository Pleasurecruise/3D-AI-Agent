# 3D-AI-Agent
## Overview

This project aims to create an AI agent capable of expressing a range of emotions through facial expressions and tone of voice, using Large Language Models (LLMs) and Large Vision Models (LVMs). 

The agent will feature a 3D face model for realistic visualization, enhancing emotional authenticity and interaction. By tackling the challenges of real-time emotion synthesis, this project offers students hands-on experience with advanced AI, visual modelling, and natural language processing to build a more life-like and empathetic AI interaction.

Tasks to be done:

- Develop an avatar with the ability to display a range of facial expressions using Unity3D.
- Integrate LLMs (such as Chat GPT) into the avatar to enable voice interaction accompanied by corresponding facial expressions.
- Upon successful completion of the above, implement additional hand gestures to “upgrade” the avatar.

## Technology Stack

- unity3d
  1. Unity3D
  2. C#
- server
  1. Python 3.12
  2. `Flask` build RESTful API
  3. `Flask-SocketIO` Implement WebSocket communication
  4. `OpenAI API` Natural language processing and sentiment analysis
  5. `Google Cloud Text-to-Speech` text to speech service
  6. `DeepFace` people facial recognition
  7. `TextBlob` basic emotion analysis
  8. `Pillow` picture processing
  9. `numpy` numerical calculation

## Plan

The project is scheduled to run from 17 February 2025 to 30 May 2025.

- 3D modeler
- Fronted Developer
- Server Developer
- AI & Model Integration Specialist
- Testing & Deployment Specialist

## TODO List

- [ ] Group Meeting

## Contributor

- `Minpei LIN`
- `Shuo ZHONG`
- `Yiming WANG`
- `Yihan ZHANG`
- `Zigeng GUO`

supervisor: BOON GIIN LEE
